# 框架轻量化使用简明文档

此文档用于说明如何使用基于[nnUNet](https://github.com/MIC-DKFZ/nnUNet)的此框架对[MICCAI 2021 FLARE Challenge:
Fast and Low GPU memory Abdominal oRgan sEgmentation](https://flare.grand-challenge.org/)数据集进行分割。由于新冠肺炎病变数据集以及框架的安装步骤等与前述章节有所重复，因此仅做必要的部分说明。

## 数据集的获取

腹部多器官的开源数据集其实不少，其中最耳熟能详的莫过于kits19。但对这些数据集进行设计的神经网络都仅仅只考虑了分割指标，没有对医院部署中的硬件指标进行考虑，有脱离实际生产需要的嫌疑。因此，MICCAI 2021 FLARE Challenge首次提出了将推理速度综合进来考虑的轻量化竞赛。当然，目前学术界还没有对医学图像的轻量化建立标准，因此轻量化到什么程度最佳，时间换空间的最佳折中点在哪里还没有清晰的认识，因此此次比赛只能说是起到抛砖引玉的作用。

数据集的[官网地址](https://flare.grand-challenge.org/)如上，具体获取方法可以参考前述的对应章节。

## 框架的安装

框架的安装可以参考前述的对应章节以及我[开源的仓库](https://github.com/tea321000/flare21_solution)：

### 从源码安装(推荐)

1. 克隆仓库以及其子仓库 (nnUNet):
    
    ```bash
    git clone --recursive https://github.com/tea321000/paper_code
    cd paper_code
    # if you are updating an existing checkout
    git submodule sync
    git submodule update --init --recursive --jobs 0
    ```
    
2. 参照[原nnUNet仓库](https://github.com/MIC-DKFZ/nnUNet#installation)的安装教程来安装修改后的nnUNet框架。确保相关的环境变量已经设置好（也可以通过写入到.bashrc来持久化这些环境变量，否则仅在terminal的session上下文中有效）:
    
    ```bash
    # some APIs in the recently updated version of batchgenerators have changed, so it is recommended to use the old version
    pip install batchgenerators==0.21
    cd flare21_solution/nnUNet
    pip install -e .
    # you can write environment variables into .bashrc
    export nnUNet_raw_data_base="/media/fabian/nnUNet_raw"
    export nnUNet_preprocessed="/media/fabian/nnUNet_preprocessed"
    export RESULTS_FOLDER="/media/fabian/nnUNet_trained_models"
    # check if the environment variable has been set
    echo $nnUNet_raw_data_base
    echo $nnUNet_preprocessed
    echo $RESULTS_FOLDER
    ```
    

### docker

我也提供了[docker镜像](https://drive.google.com/file/d/1a-atCB_BZkeyzrho2ediEtLzt6rk6YT4/view)作为其中的一种安装方式，但这种方式不太利用修改和开发，需要对docker的配置和文件映射拥有一定的熟悉能力，docker比较适用于快速验证指标的场合。可以使用以下指令进行安装:

```bash
docker image load < ttime_flare_final.tar.gz
docker container run --gpus "all" --name ttime --rm -v $PWD/inputs/:/workspace/inputs/ -v $PWD/outputs/:/workspace/outputs/ teamname:latest /bin/bash -c "sh predict.sh"
```

## 框架的使用

框架使用的详情可以查看前述的对应章节。此处仅介绍不同之处。

### 任务的建立和预处理

此任务中，只具有CT单模态体素图像，标签类别包括背景、肝脏、肾脏、脾脏和胰腺五种类别。根据这一特点，编写转换脚本：

```bash
cd ..
#修改downloaded_data_dir为数据集下载路径，Task id默认为601
vim abdomen1KCT_conversion.py
#进行转换
python abdomen1KCT_conversion.py
```

### 框架的使用

框架的轻量化分为两个阶段，第一部分为框架的训练阶段，第二部分为框架的测试阶段。训练阶段与前述章节没有太大差别，仅需要替换为`nnUNetTrainerV2_flare`训练器：

```bash
# my solution in challenge uses lowres network, but fullres network can also be used
nnUNet_train 3d_lowres nnUNetTrainerV2_flare TaskXXX_MYTASK FOLD --npz
```

测试阶段需要先对模型权重进行算子融合才能进行测试。通过编写脚本，可以方便地将训练好的模型权重进行标准化算子与卷积算子的融合：

```bash
#为防止误操作，可在融合前备份模型权重
python rep_model_convert.py -c checkpoint -o output_checkout -on output_checkout_name
#手动进行模型权重的替换，替换后进行正常的预测
nnUNet_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -t 601 -m 3d_lowres -tr nnUNetTrainerV2_flare -f 4
```

### （可选）读取训练权重进行预测

当然，也可以使用预先提供的训练模型进行预测：

1. 通过 [download.sh](https://github.com/tea321000/flare21_solution/blob/main/download.sh) 脚本或者 [Google Drive](https://drive.google.com/file/d/1YW8MsLaYUr6lhfpf_LL6kTelPiuJRhq9/view) 链接下载模型(任务 id 为500):
    
    ```bash
    bash download.sh
    ```
    
    假如从Google Drive进行下载，你会需要手动解压文件到`flare21_solution` 文件夹中的`trained_weight` 子文件夹并运行[download.sh](https://github.com/tea321000/flare21_solution/blob/main/download.sh).
    
2. 在 `flare21_solution`文件夹下创建 `inputs` 子文件夹，然后将需要预测的样本放入其中，然后运行 [predict.sh](https://github.com/tea321000/flare21_solution/blob/main/predict.sh):

```bash
bash predict.sh
```